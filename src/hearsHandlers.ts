import { Composer } from 'telegraf'
import { MyContext } from './interfaces'
import { imageModelMenu } from './menu/imageModelMenu'

import { balanceCommand } from './commands/balanceCommand'
import { generateTextToImage } from './services/generateTextToImage'
import { isRussian } from './helpers/language'

import { generateNeuroImage } from './services/generateNeuroImage'

import { handleSizeSelection } from './handlers'
import { levels, mainMenu } from './menu'
import { getReferalsCountAndUserData } from './core/supabase'

export const myComposer = new Composer<MyContext>()

myComposer.hears([levels[1].title_ru, levels[1].title_en], async ctx => {
  console.log('CASE: ðŸ§  ÐœÐ¾Ð·Ð³ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°')
  ctx.session.mode = 'avatar'

  await ctx.scene.enter('avatarWizard')
})

myComposer.hears([levels[2].title_ru, levels[2].title_en], async ctx => {
  console.log('CASE: ðŸ’­ Ð§Ð°Ñ‚ Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð¾Ð¼')
  ctx.session.mode = 'chat_with_avatar'
  await ctx.scene.enter('chatWithAvatarWizard')
})

myComposer.hears([levels[3].title_ru, levels[3].title_en], async ctx => {
  console.log('CASE: ðŸ¤– Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð˜Ð˜')
  ctx.session.mode = 'select_model'
  await ctx.scene.enter('selectModelWizard')
})

myComposer.hears([levels[4].title_ru, levels[4].title_en], async ctx => {
  console.log('CASE: ðŸ¤– Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ðµ Ñ‚ÐµÐ»Ð¾')
  ctx.session.mode = 'digital_avatar_body'
  await ctx.scene.enter('digitalAvatarBodyWizard')
})

myComposer.hears([levels[5].title_ru, levels[5].title_en], async ctx => {
  console.log('CASE: ðŸ“¸ ÐÐµÐ¹Ñ€Ð¾Ñ„Ð¾Ñ‚Ð¾')
  ctx.session.mode = 'neuro_photo'
  await ctx.scene.enter('neuroPhotoWizard')
})

myComposer.hears([levels[6].title_ru, levels[6].title_en], async ctx => {
  console.log('CASE: ðŸ” ÐŸÑ€Ð¾Ð¼Ð¿Ñ‚ Ð¸Ð· Ñ„Ð¾Ñ‚Ð¾')
  ctx.session.mode = 'image_to_prompt'
  await ctx.scene.enter('imageToPromptWizard')
})

myComposer.hears([levels[7].title_ru, levels[7].title_en], async ctx => {
  console.log('CASE: ðŸŽ¤ Ð“Ð¾Ð»Ð¾Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°')
  ctx.session.mode = 'voice'
  await ctx.scene.enter('voiceAvatarWizard')
})

myComposer.hears([levels[8].title_ru, levels[8].title_en], async ctx => {
  console.log('CASE: ðŸŽ™ï¸ Ð¢ÐµÐºÑÑ‚ Ð² Ð³Ð¾Ð»Ð¾Ñ')
  ctx.session.mode = 'text_to_speech'
  await ctx.scene.enter('textToSpeechWizard')
})

myComposer.hears([levels[9].title_ru, levels[9].title_en], async ctx => {
  console.log('CASE: ðŸŽ¥ Ð¤Ð¾Ñ‚Ð¾ Ð² Ð²Ð¸Ð´ÐµÐ¾')
  ctx.session.mode = 'image_to_video'
  await ctx.scene.enter('imageToVideoWizard')
})

myComposer.hears([levels[10].title_ru, levels[10].title_en], async ctx => {
  console.log('CASE: ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°')
  ctx.session.mode = 'text_to_video'
  await ctx.scene.enter('textToVideoWizard')
})

myComposer.hears([levels[11].title_ru, levels[11].title_en], async ctx => {
  console.log('CASE: ðŸ–¼ï¸ Ð¢ÐµÐºÑÑ‚ Ð² Ñ„Ð¾Ñ‚Ð¾')
  ctx.session.mode = 'text_to_image'
  await ctx.scene.enter('textToImageWizard')
  await imageModelMenu(ctx)
})

myComposer.hears(['ðŸŽ¤ Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð³ÑƒÐ±', 'ðŸŽ¤ Lip Sync'], async ctx => {
  console.log('CASE: Ð¡Ð¸Ð½Ñ…Ñ€Ð¾Ð½Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð³ÑƒÐ±')
  ctx.session.mode = 'lip_sync'
  await ctx.scene.enter('lipSyncWizard')
})

myComposer.hears(['â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ', 'â“ Help'], async ctx => {
  console.log('CASE: ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ')
  ctx.session.mode = 'help'
  await ctx.scene.enter('neuroQuestCommand')
})

myComposer.hears([levels[99].title_ru, levels[99].title_en], async ctx => {
  console.log('CASE: ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ')
  ctx.session.mode = 'start_learning'
  await ctx.scene.enter('step0')
})

myComposer.hears([levels[103].title_ru, levels[103].title_en], async ctx => {
  console.log('CASE: ðŸ’µ ÐžÑ„Ð¾Ñ€Ð¼Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾Ð´Ð¿Ð¸ÑÐºÐ¸')
  await ctx.scene.enter('subscriptionScene')
})

myComposer.hears([levels[100].title_ru, levels[100].title_en], async ctx => {
  console.log('CASE: ÐŸÐ¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ')
  ctx.session.mode = 'top_up_balance'
  ctx.session.subscription = 'stars'
  await ctx.scene.enter('paymentScene')
})

myComposer.hears([levels[101].title_ru, levels[101].title_en], async ctx => {
  console.log('CASE: Ð‘Ð°Ð»Ð°Ð½Ñ')
  ctx.session.mode = 'balance'
  await balanceCommand(ctx)
})

myComposer.hears([levels[102].title_ru, levels[102].title_en], async ctx => {
  console.log('CASE: ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð°')
  ctx.session.mode = 'invite'
  await ctx.scene.enter('inviteScene')
})

myComposer.hears(['ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ', 'ðŸ  Main menu'], async ctx => {
  console.log('CASE: Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ')
  ctx.session.mode = 'main_menu'
  await ctx.scene.enter('menuScene')
})

myComposer.hears(['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£'], async ctx => {
  const text = ctx.message.text
  console.log(`CASE: ÐÐ°Ð¶Ð°Ñ‚Ð° ÐºÐ½Ð¾Ð¿ÐºÐ° ${text}`)
  const isRu = isRussian(ctx)
  const prompt = ctx.session.prompt
  const userId = ctx.from.id
  const numImages = parseInt(text[0])
  console.log('ctx.session.mode', ctx.session.mode)
  // ctx.session.mode = 'text_to_image'
  const generate = async (num: number) => {
    if (ctx.session.mode === 'neuro_photo') {
      await generateNeuroImage(
        prompt,
        ctx.session.userModel.model_url,
        num,
        userId,
        ctx
      )
    } else {
      await generateTextToImage(
        prompt,
        ctx.session.selectedModel || '',
        num,
        userId,
        isRu,
        ctx
      )
    }
  }

  if (numImages >= 1 && numImages <= 4) {
    await generate(numImages)
  } else {
    await ctx.reply('ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°')
  }
})

myComposer.hears(
  ['ðŸŽ¥ Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾?', 'ðŸŽ¥ Generate new video?'],
  async ctx => {
    console.log('CASE: Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾')
    const mode = ctx.session.mode
    console.log('mode', mode)
    if (mode === 'text_to_video') {
      await ctx.scene.enter('textToVideoWizard')
    } else if (mode === 'image_to_video') {
      await ctx.scene.enter('imageToVideoWizard')
    } else {
      await ctx.reply(
        isRussian(ctx)
          ? 'Ð’Ñ‹ Ð½Ðµ Ð¼Ð¾Ð¶ÐµÑ‚Ðµ ÑÐ³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾ Ð² ÑÑ‚Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ'
          : 'You cannot generate a new video in this mode'
      )
    }
  }
)

myComposer.hears(['â¬†ï¸ Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚', 'â¬†ï¸ Improve prompt'], async ctx => {
  console.log('CASE: Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚')

  await ctx.scene.enter('improvePromptWizard')
})

myComposer.hears(['ðŸ“ Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€', 'ðŸ“ Change size'], async ctx => {
  console.log('CASE: Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€')

  await ctx.scene.enter('sizeWizard')
})

myComposer.hears(
  [
    '21:9',
    '16:9',
    '3:2',
    '4:3',
    '5:4',
    '1:1',
    '4:5',
    '3:4',
    '2:3',
    '9:16',
    '9:21',
  ],
  async ctx => {
    console.log('CASE: Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€')
    const size = ctx.message.text
    await handleSizeSelection(ctx, size)
  }
)

myComposer.hears(
  ['ðŸŽ¥ Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾', 'ðŸŽ¥ Generate new video'],
  async ctx => {
    console.log('CASE: Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾')
    ctx.session.mode = 'text_to_video'
    await ctx.scene.enter('textToVideoWizard')
  }
)

myComposer.hears(/^(ÐžÑ‚Ð¼ÐµÐ½Ð°|Ð¾Ñ‚Ð¼ÐµÐ½Ð°|Cancel|cancel)$/i, async ctx => {
  console.log('CASE: ÐžÑ‚Ð¼ÐµÐ½Ð°')
  const isRu = isRussian(ctx)
  const telegram_id = ctx.from?.id?.toString() || ''
  const { count, subscription } = await getReferalsCountAndUserData(telegram_id)
  await mainMenu(isRu, count, subscription)
  return ctx.scene.leave()
})

myComposer.hears(['Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ', 'Help for the command'], async ctx => {
  console.log('CASE: Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ')
  await ctx.scene.enter('helpScene')
})
